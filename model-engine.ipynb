{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ed4c2a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-16T14:57:47.509118Z",
     "iopub.status.busy": "2024-02-16T14:57:47.508560Z",
     "iopub.status.idle": "2024-02-16T14:58:00.063305Z",
     "shell.execute_reply": "2024-02-16T14:58:00.062448Z"
    },
    "papermill": {
     "duration": 12.562737,
     "end_time": "2024-02-16T14:58:00.065967",
     "exception": false,
     "start_time": "2024-02-16T14:57:47.503230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "    \n",
    "import timm\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except:\n",
    "    !pip install wandb\n",
    "    import wandb\n",
    "# wandb.login()\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Contains functions for training and testing a PyTorch model.\n",
    "\"\"\"\n",
    "from torchinfo import summary\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "import logging\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class CheckpointSaver:\n",
    "    def __init__(self, dirpath, decreasing=True, top_n=5):\n",
    "        \"\"\"\n",
    "        dirpath: Directory path where to store all model weights \n",
    "        decreasing: If decreasing is `True`, then lower metric is better\n",
    "        top_n: Total number of models to track based on validation metric value\n",
    "        \"\"\"\n",
    "        if not os.path.exists(dirpath): os.makedirs(dirpath)\n",
    "        self.dirpath = dirpath\n",
    "        self.top_n = top_n \n",
    "        self.decreasing = decreasing\n",
    "        self.top_model_paths = []\n",
    "        self.best_metric_val = np.Inf if decreasing else -np.Inf\n",
    "        \n",
    "    def __call__(self, model, epoch, metric_val):\n",
    "        model_path = os.path.join(self.dirpath, model.__class__.__name__ + f'_epoch{epoch}.pt')\n",
    "        save = metric_val<self.best_metric_val if self.decreasing else metric_val>self.best_metric_val\n",
    "        if save: \n",
    "            logging.info(f\"Current metric value better than {metric_val} better than best {self.best_metric_val}, saving model at {model_path}\")\n",
    "            self.best_metric_val = metric_val\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            self.top_model_paths.append({'path': model_path, 'score': metric_val})\n",
    "            self.top_model_paths = sorted(self.top_model_paths, key=lambda o: o['score'], reverse=not self.decreasing)\n",
    "        if len(self.top_model_paths)>self.top_n: \n",
    "            self.cleanup()\n",
    "            \n",
    "    def log_artifact(self, filename, model_path, metric_val):\n",
    "        artifact = wandb.Artifact(filename, type='model', metadata={'Validation score': metric_val})\n",
    "        artifact.add_file(model_path)\n",
    "        wandb.run.log_artifact(artifact)  \n",
    "\n",
    "    \n",
    "    def cleanup(self):\n",
    "        to_remove = self.top_model_paths[self.top_n:]\n",
    "        logging.info(f\"Removing extra models.. {to_remove}\")\n",
    "        for o in to_remove:\n",
    "            os.remove(o['path'])\n",
    "        self.top_model_paths = self.top_model_paths[:self.top_n]\n",
    "\n",
    "\n",
    "class Engine():\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 loss_fn,\n",
    "                 optimizer,\n",
    "                 device,\n",
    "                 dirpath,\n",
    "                 early_stopping = False,\n",
    "                 config = None):\n",
    "\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "        self.early_stopping = early_stopping\n",
    "        self.counter = 0\n",
    "        self.early_stop = False # type: ignore\n",
    "        self.best_score = None\n",
    "        \n",
    "        self.dirpath = dirpath\n",
    "\n",
    "        # Copy your config\n",
    "        self.config = config\n",
    "\n",
    "    def model_summary(self,\n",
    "                      input_size,\n",
    "                      col_width = 20,):\n",
    "\n",
    "        return summary(self.model,\n",
    "                input_size = input_size, # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
    "                col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "                col_width = col_width,\n",
    "                row_settings = [\"var_names\"])\n",
    "    \n",
    "    def confusion_matrix(self):\n",
    "        # constant for classes\n",
    "        classes = ('OSCC', 'With Dysplasia', 'Without Dysplasia')\n",
    "\n",
    "        # Build confusion matrix\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                             columns = [i for i in classes])\n",
    "        plt.figure(figsize = (12,7))\n",
    "        sns.heatmap(df_cm, annot=True)\n",
    "        plt.savefig('/kaggle/working/output.png')\n",
    "    \n",
    "\n",
    "    def check_early_stop(self,\n",
    "                   val_loss,\n",
    "                   delta,\n",
    "                   verbose,\n",
    "                   patience):\n",
    "\n",
    "        score = -val_loss\n",
    "        # print(verbose)\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "\n",
    "        elif score < self.best_score + delta:\n",
    "            self.counter += 1\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Early stopping counter: {self.counter} out of {patience}\")\n",
    "\n",
    "            if self.counter >= patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.early_stop = False\n",
    "            self.counter = 0\n",
    "\n",
    "    # convenience funtion to log predictions for a batch of test images\n",
    "    def log_test_predictions(self, images, labels, outputs, predicted, test_table, log_counter):\n",
    "        #  obtain confidence scores for all classes\n",
    "        scores = F.softmax(outputs.data, dim=1)\n",
    "        log_scores = scores.cpu().numpy()\n",
    "        log_images = images.cpu().numpy()\n",
    "        log_labels = labels.cpu().numpy()\n",
    "        log_preds = predicted.cpu().numpy()\n",
    "        # adding ids based on the order of the images\n",
    "        _id = 0\n",
    "        for i, l, p, s in zip(log_images, log_labels, log_preds, log_scores):\n",
    "            # add required info to data table:\n",
    "            # id, image pixels, model's guess, true label, scores for all classes\n",
    "            img_id = str(_id) + \"_\" + str(log_counter)\n",
    "            img = i.transpose(1, 2, 0)\n",
    "            test_table.add_data(img_id, wandb.Image(img), p, l, *s)\n",
    "            _id += 1\n",
    "            if _id == self.config.batch_size:\n",
    "                break\n",
    "\n",
    "            \n",
    "    def train_step(self, epoch):\n",
    "#         correct = 0\n",
    "        y_tr_true, y_tr_pred= [], []\n",
    "        # Put model in train mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Setup train loss and train accuracy values\n",
    "        train_loss, train_acc = 0, 0\n",
    "\n",
    "        n_steps_per_epoch = math.ceil(len(self.train_dataloader) / self.config.batch_size)\n",
    "\n",
    "        # Loop through data loader data batches\n",
    "        for i, data in enumerate(tqdm(self.train_dataloader, desc=f'Epoch {epoch + 1}/{self.epochs}', unit='batch')):\n",
    "            # Send data to target device\n",
    "            X_train, y_train = data\n",
    "            \n",
    "            y_tr_true.extend(y_train) # collect all training labels\n",
    "\n",
    "            X_train = X_train.to(self.device)\n",
    "            y_train = y_train.to(self.device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "\n",
    "            outputs = self.model(X_train)\n",
    "            _, y_pred = torch.max(outputs, 1) # max along an axis gives both max val as well as index\n",
    "            y_tr_pred.extend(y_pred.data.cpu())\n",
    "\n",
    "            # 2. Calculate  and accumulate loss\n",
    "            loss = self.loss_fn(outputs, y_train)\n",
    "\n",
    "            train_loss += loss.item() \n",
    "\n",
    "            # 3. Optimizer zero grad\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # 4. Loss backward\n",
    "            loss.backward()\n",
    "\n",
    "            # 5. Optimizer step\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        # Adjust metrics to get average loss and accuracy per batch\n",
    "        train_loss /= len(self.train_dataloader)\n",
    "        train_acc = accuracy_score(y_tr_true, y_tr_pred)\n",
    "\n",
    "\n",
    "        # Log Training info in W&B\n",
    "        metrics ={\n",
    "                      \"train/train_loss\": train_loss,\n",
    "                      \"train/epoch\": (i + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch,\n",
    "                      \"train/train_acc\": train_acc,\n",
    "                  }\n",
    "        if self.config:\n",
    "            wandb.log(metrics)\n",
    "\n",
    "        return train_loss, train_acc\n",
    "\n",
    "\n",
    "    def test_step(self, epoch):\n",
    "\n",
    "        y_ts_true,  y_ts_pred = [], []\n",
    "        log_counter = 0\n",
    "        # Put model in eval mode\n",
    "        \n",
    "        columns=[\"Id\", \"Image\", \"Predicted\", \"Actual\"]\n",
    "        for digit in range(3):\n",
    "            columns.append(\"score_\" + str(digit))\n",
    "        test_table = wandb.Table(columns=columns)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        # Setup test loss and test accuracy values\n",
    "        test_loss, test_acc = 0, 0\n",
    "\n",
    "        # Turn on inference context manager\n",
    "        with torch.inference_mode():\n",
    "            # Loop through DataLoader batches\n",
    "            for i, data in enumerate(tqdm(self.test_dataloader, desc=f'Epoch {epoch + 1}/{self.epochs}', unit='batch')):\n",
    "                # Send data to target device\n",
    "                X_test, y_test = data\n",
    "                y_ts_true.extend(y_test) # collect all training labels\n",
    "\n",
    "                y_test = y_test.to(self.device)\n",
    "                X_test = X_test.to(self.device)\n",
    "\n",
    "                # 1. Forward pass\n",
    "                outputs = self.model(X_test)\n",
    "                _, y_pred = torch.max(outputs, 1) # max along an axis gives both max val as well as index\n",
    "\n",
    "                y_ts_pred.extend(y_pred.data.cpu())\n",
    "\n",
    "                # 2. Calculate and accumulate loss\n",
    "                loss = self.loss_fn(outputs, y_test)\n",
    "                test_loss += loss.item() \n",
    "\n",
    "                # Calculate and accumulate accuracy\n",
    "                self.log_test_predictions(X_test, y_test, outputs, y_pred, test_table, log_counter)\n",
    "                log_counter += 1\n",
    "\n",
    "         # âœ¨ W&B: Log predictions table to wandb\n",
    "        wandb.log({\"test_predictions\" : test_table})\n",
    "        \n",
    "        # Adjust metrics to get average loss and accuracy per batch\n",
    "        test_loss/= len(self.test_dataloader)\n",
    "        test_acc = accuracy_score(y_ts_true, y_ts_pred)\n",
    "\n",
    "\n",
    "\n",
    "        # Log Testing info in W&B\n",
    "        metrics ={\n",
    "                  \"test/test_loss\": test_loss,\n",
    "                  \"test/test_acc\": test_acc,\n",
    "                  }\n",
    "\n",
    "        if self.config:\n",
    "            wandb.log(metrics)\n",
    "            \n",
    "        \n",
    "\n",
    "        return test_loss, test_acc\n",
    "\n",
    "\n",
    "    def evaluate(self,\n",
    "                eval_dataloader):  \n",
    "        \n",
    "        self.eval_dataloader = eval_dataloader\n",
    "        \n",
    "        y_ts_true,  y_ts_pred = [], []\n",
    "        \n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "        running_loss =  0.0\n",
    "        correct_predictions =  0\n",
    "        total_predictions =  0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation\n",
    "            for i, data in enumerate(tqdm(self.eval_dataloader, unit='batch')):\n",
    "                \n",
    "                inputs, labels = data\n",
    "                \n",
    "                y_ts_true.extend(labels)\n",
    "                \n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "                # Compute the loss and update the running loss\n",
    "                running_loss += loss.item() \n",
    "\n",
    "                # Compute the number of correct predictions\n",
    "                _, y_pred = torch.max(outputs,  1)\n",
    "                y_ts_pred.extend(y_pred.data.cpu())\n",
    "\n",
    "        # Compute the average loss and accuracy\n",
    "        avg_loss = running_loss / len(self.eval_dataloader)\n",
    "\n",
    "        return avg_loss, (y_ts_true, y_ts_pred)\n",
    "    \n",
    "    def train(self,\n",
    "              train_dataloader,\n",
    "              test_dataloader,\n",
    "              epochs=1,\n",
    "              delta = 0,\n",
    "              patience = 10,\n",
    "              verbose = False):\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        # Create empty results dictionary\n",
    "        results = {\"epoch\":[],\n",
    "                \"train_loss\": [],\n",
    "                \"train_acc\": [],\n",
    "                \"test_loss\": [],\n",
    "                \"test_acc\": []\n",
    "        }\n",
    "\n",
    "        # Make sure model on target device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        checkpoint_saver = CheckpointSaver(dirpath=self.dirpath, decreasing=True, top_n=5)\n",
    "        \n",
    "        # Loop through training and testing steps for a number of epochs\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, train_acc = self.train_step(epoch)\n",
    "            test_loss, test_acc = self.test_step(epoch)\n",
    "\n",
    "            # Print out what's happening\n",
    "            print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Update results dictionary\n",
    "            results[\"epoch\"].append(epoch+1)\n",
    "            results[\"train_loss\"].append(train_loss)\n",
    "            results[\"test_loss\"].append(test_loss)\n",
    "            results[\"train_acc\"].append(train_acc)\n",
    "            results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "            checkpoint_saver(self.model, epoch+1, test_loss)\n",
    "\n",
    "            if self.early_stopping:\n",
    "                self.check_early_stop(test_loss, delta, verbose, patience)\n",
    "                if self.early_stop:\n",
    "                    print(\"Early Stopping\")\n",
    "                    break\n",
    "\n",
    "        # Mark the run as finished\n",
    "        wandb.finish()\n",
    "        # Return the filled results at the end of the epochs\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.166921,
   "end_time": "2024-02-16T14:58:02.543571",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-16T14:57:44.376650",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
